{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1eb25fa",
   "metadata": {},
   "source": [
    "# Esercitazione 12: Convolutional neural networks per il riconoscimento di immagini\n",
    "In questa esercitazione si costruiscono, testano e utilizzano DNN e DCNN per il riconoscimento di immagini. Lo scopo finale è costruire una rete in grado di riconoscere le cifre $[0-9]$ scritte a mano. Abbiamo utilizzato il database MNIST, che comprende $70000$ immagini di cifre scritte a mano e classificate, per allenare e per provare il modello. In particolare, le immagini sono di 28X28 pixel con una sola banda (scala di grigi). Il valore di ciascun pixel va da $0$ (bianco) a $255$ (nero): in questa esercitazione abbiamo rinormalizzato i valori per averli in $[0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2af3fa",
   "metadata": {},
   "source": [
    "## Esercizio 12.1\n",
    "Si vogliono testare le caratteristiche e l'efficacia di alcuni ottimizzatori. Manteniamo i parametri di questa rete fissati:\n",
    "- $60000$ dati di training, $10000$ dati di validazione\n",
    "- $N_{epoch}=5$\n",
    "\n",
    "La rete neurale utilizzata è strutturata nel seguente modo:\n",
    "- input: $28\\times28=784$ valori\n",
    "- layer denso all-to-all di $400$ neuroni\n",
    "- layer denso all-to-all di $100$ neuroni\n",
    "- layer di dropout con probabilità $50\\%$\n",
    "- layer denso all-to-all di $10$ neuroni (layer di output: ogni neurone corrisponde a una cifra, e la sua attivazione indica quanto l'input corrisponde alla cifra a cui è associato)\n",
    "\n",
    "Riportiamo i risultati relativi all'evoluzione della funzione di costo e alla accuracy (pari al numero di volte in cui un'immagine è classificata correttamente diviso il totale di classificazioni effettuate) per gli ottimizzatori scelti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5bc71d",
   "metadata": {},
   "source": [
    "#### SGD\n",
    "![alt_text](img/12.1/SGD.png \"\")\n",
    "\n",
    "Si nota come la precisione di classificazione sui dati di validazione (test) sia maggiore di quella durante il training. Questo è dovuto al layer di Dropout, che \"spegne\" alcuni neuroni durante la fase di training (diminuendo l'accuratezza della rete in quel momento, ma forzando i neuroni rimanenti ad imparare meglio).Durante il test tutti i neuroni sono invece attivi, quindi la precisione è maggiore di quella del training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d816358",
   "metadata": {},
   "source": [
    "#### Adam\n",
    "![alt_text](img/12.1/adam.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb29db4",
   "metadata": {},
   "source": [
    "#### RMSprop\n",
    "![alt_text](img/12.1/RMSprop.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ac301",
   "metadata": {},
   "source": [
    "In entrambi i casi, la precisione di classificazione aumenta rispetto all'SGD. Tuttavia si nota in maniera meno evidente l'effetto del layer di dropout in questi casi: l'accuratezza nel classificare i dati di test è di poco superiore a quella di training nel caso dell'RMSprop e addirittura inferiore utilizzando l'algoritmo Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396bc16e",
   "metadata": {},
   "source": [
    "## Esercizio 12.2\n",
    "Se nell'esercizio 12.1 abbiamo considerato le immagini come vettori 1-D di $28\\times28=784$ pixel, sarebbe certamente utile sfruttare le invarianze traslazionali e correlazioni spaziali locali che ci aspettiamo di trovare nell'immagine di una cifra scritta a mano. Questa caratteristica si può realizzare utilizzando dei layer convoluzionali. Oltre a questi utilizziamo dei filtri (MaxPooling) che diminuiscono la dimensionalità dell'immagine originaria. Una combinazione di layer di questo tipo dovrebbe ruiscire a individuare i pattern spaziali che caratterizzano le cifre scritte. I dati processsati vengono poi trasformati in un vettore 1-D tramite il layer Flatten ed ulteriormente analizzati dal resto della rete. L'ultimo layer conterrà necessariamente 10 neuroni (di output). Essendo notoriamente efficiente in problemi di classificazione la funzione di attivazione per l'ultimo layer è di solito _softmax_. Con una rete di questo tipo dovremmo riuscire ad aumentare l'accuratezza rispetto alle reti non convoluzionali considerate fino ad ora.\n",
    "\n",
    "La struttura dettagliata è schematizzata qui sotto:\n",
    "- Layer convoluzionale con 10 filtri (è necessario che siano lo stesso numero dei possibili output)\n",
    "- Layer di pooling\n",
    "- Layer convoluzionale con 10 filtri\n",
    "- Layer di appiattimento (Flatten)\n",
    "- Layer denso all-to-all di 20 neuroni\n",
    "- Layer denso all-to-all di 20 neuroni\n",
    "- Layer di dropout (con probabilità $50\\%$)\n",
    "- Layer di output denso all-to-all\n",
    "\n",
    "I layer convoluzionali e densi (tranne l'ultimo) hanno funzione di attivazione _relu_. Abbiamo scelto l'ottimizzatore SGD e $8$ epoche per allenare l'algoritmo.\n",
    "\n",
    "Riportiamo la evoluzione della funzione di costo e della accuratezza:\n",
    "![alt_text](img/12.2/SGDmodel.png \"\")\n",
    "Si osserva un notevole miglioramento dell'accuratezza sui dati di test, prova dell'efficacia del layer di dropout.\n",
    "\n",
    "Infine, mostriamo la classificazione di alcune delle immagini nel campione di validazione.\n",
    "![alt_text](img/12.2/classification.png \"\")\n",
    "Tutte le cifre sono state classificate correttamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161515c",
   "metadata": {},
   "source": [
    "## Esercizio 12.3\n",
    "Il modello viene infine utilizzato per classificare le cifre scritte a mano dall'autore e da alcuni amici. Riportiamo i risultati in questa immagine:\n",
    "![alt_text](img/12.3/classification.png \"\")\n",
    "Tutte le cifre sono state riconosciute.\n",
    "![alt_text](img/12.3/friends/classification.png \"\")\n",
    "In questo caso tutte le cifre tranne una sono state riconosciute. Si riesce a intuire perché: il 5 e il 6 sono disegnati in maniera molto simile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064623c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
